# HTRC API

* [HathiTrust Digital Library](https://www.hathitrust.org/digital_library)
* [HathiTrust Research Center](https://analytics.hathitrust.org/)
    * The HathiTrust Research Center (HTRC) enables computational analysis of the HathiTrust corpus.
    * Log in with your partner institution (SMU) account to access the largest number of volumes and features.
    * [Click here for a list of HTRC tutorials to walk you through the steps for using HTRC tools and data.](https://wiki.htrc.illinois.edu/display/COM/All+HTRC+Tutorials)

##  HTRC for Text Analysis
* [HTRC Algorithms](https://analytics.hathitrust.org/statisticalalgorithms) are web-based, click-and-run tools to perform computational text analysis on volumes in the HathiTrust Digital Library. 

![HTRC for text analysis](../images/htrcta.png)

* In a basic text analysis workflow, a researcher:
    * Gathers digitized text (text that has been scanned and OCR-ed) Note: OCR (Optical character recognition) refers to the mechanical or electronic conversion of images of typed, handwritten or printed text into machine-encoded text. 
     * Applies computational methods to that text, such as word counts, classification techniques, and topic modeling
    * And then analyzes the results generated by the algorithm or technique

* HathiTrust Research Center (HTRC) enters the workflow *at the points of providing digitized text at scale* from HathiTrust Digital Library (HTDL) and providing tools and services that enable computational research. 
* The researcher, of course, still brings her own analysis to bear on the results.




## API (application programming interface)

An application programming interface (API) is a way for two or more computer programs or components to communicate with each other.


Additional Explanation form technology companies: 
- Postman: [video explanation of API](https://youtu.be/-0MmWEYR2a8?si=ilGP5D2w71AEdZHh), [Text explanation of API](https://www.postman.com/what-is-an-api/)
- IBM: [text explanation of API](https://www.ibm.com/topics/api)


Example APIs: loc.gov
- For example, look at these pages from the Library of Congress
- The [main page](https://www.loc.gov/) is meant for people to interact with. 
- The [APIs for LoC.gov](https://www.loc.gov/apis/) "makes information available via a series of application programming interfaces (APIs)" it is meant to retrieve information from Loc.gov in a way that is formatted for a machine and for a programming interface.  
- [Library of Congress Data Exploration](https://github.com/LibraryOfCongress/data-exploration?tab=readme-ov-file#library-of-congress-data-exploration)




### HTRC Extracted Features (EF) API

The HTRC Extracted Features Dataset v.2.0 is composed of page-level features for 17.1 million volumes in the HathiTrust Digital Library. This version contains non-consumptive features for both public-domain and in-copyright books.
Features include part-of-speech tagged term token counts, header/footer identification, marginal character counts, and much more.


* [HTRC Extracted Features (EF) Dataset](https://analytics.hathitrust.org/deriveddatasets#ef)
* A full explanation of the dataset's features, motivation, and creation is available at the EF Dataset documentation page: [HTRC Extracted Features (EF) Documentation](https://htrc.atlassian.net/wiki/spaces/COM/pages/43295914/Extracted+Features+v.2.0/)
* [EF API](https://htrc.stoplight.io/docs/ef-api/8xpvh96ani2e0-ef-api) 



#### Worksets
[Ready-Made Featured Worksets](https://htrc.github.io/torchlite-handbook/worksets.html)

# TORCHLITE 

[TORCHLITE Hackathon Handbook](https://htrc.github.io/torchlite-handbook/)
[Torchlite API Documentation](https://torchlite-dev-api.htrc.illinois.edu/docs#/)





# Login to HTDL & HTRC 
## First, go to the HathiTrust Digital Library (HTDL) interface. 
* [Go to HTDL site](https://www.hathitrust.org/)
* Click on the “LOG IN” button on the right to sign in.
* If you are affiliated to an HT partner institution (such as SMU), select your partner institution from the list and click on continue, then follow the directions for institutional log in.
* Once you are logged in, click on the “FULL-TEXT” tab to search in full text. Now you can start thinking about a search query to find volumes for your collection. Try building your own collection.
* View search results. You can facet in the sidebar, then select volumes.
* When you’re satisfied with your selection, click on the “Select Collection” bar and choose “[CREATE NEW COLLECTION]” from the drop-down menu. Then hit the “Add Selected” button on the right. 
* A pop-up window will appear that prompts you to add some metadata to your collection before the system creates it for you. 
    * Fill in the name and description of your new collection. 
    * You can choose to make the collection public or private, and we recommend writing a short description whenever you make collections public. 
    * When done, click on “Save Changes” to create your collection.
* After the collection is successfully created, you should see a a confirmation message above the search results. 
    * To view your collection, click on “My Collections” near the top right of the page. 
* This will bring you to all your collections. 
    *You can manage your collections here by viewing collections, changing the public or private status of a collection, and deleting collections you don’t need. 
    * Click on the title of the collection you just created to view it. 
    * While viewing a collection, you will see *Collection Tools*
        * There will be an option for a sharable link to this collection (only sharable and usable in HTRC if you choose to make your collections public)
* You will be able to see the title and description of your collection, as well as all the items in it. 
    *   In order to import your newly created collection into HTRC Analytics for analysis, we need to download the metadata of the collection first. 
        * Click on the “Download Metadata” button on the left sidebar and select the “Download Item Metadata: Tab-Delimited Text (TSV)” option. 
            * You will not be able to upload the JSON metadata of your collection to HTRC Analytics, so make sure to select the TSV option.


## Second, go to the HathiTrust Research Center (HTRC) Analytics interface. 
* Go to [HTRC Analytics](https://analytics.hathitrust.org/)
* Look for the sign in/ sign up section on the top right part of the page.
    * If you are affiliated to an HT partner institution (such as SMU), select your partner institution from the list and click on continue, then follow the directions for institutional log in. [FAQ page for sign in](https://wiki.htrc.illinois.edu/display/COM/Troubleshooting+and+FAQs#TroubleshootingandFAQs-UserAccountsandSign-in)
* **Workset**: Now, we are ready to import our HT Collection into HTRC Analytics as a workset. 
    * Click on the [“Worksets” option on the header menu.](https://analytics.hathitrust.org/worksets) 
        * Click on *Create A Workset.* 
* Import from file:
    * To create a workset from a file of HathiTrust volume IDs ( in the TSV file you created in step 1) click on *upload file.*
* Name your workset and write a description if you like. 
    * When naming, please note that only characters A-Z, 0-9, (), -, or _  are allowed, so do not use spaces or other special characters. 
    * Click on “Choose file” to upload the TSV file we just downloaded. 
    * Check the “Make private workset” box if you want to create a private workset. 
    * Finally, hit the “Create Workset” button. 
* If successful, you should be brought back to your worksets page, and the new workset that you just created should be listed. 
    * Click on the name of the workset to view it. 
* Import from Hathitrust:
 * Create a workset from an existing, public HathiTrust collection
 * You will need the URL for a public HathiTrust collection. Private collections cannot be imported by URL.
    * After entering the URL, click on Fetch collection. after the collections is successfully fetched, you will see the text *Data retrieved from source*  
    * Enter Name and Description, then click on Create Workset. 
* **Algorithms**: Now, we are ready to apply HTRC Algorithms to our worksets.  
    * Click on the [“Algorithm” option on the header menu.](https://analytics.hathitrust.org/algorithms) 
        * Choose one of the Algorithms to Execute. 
            * If you have questions about what preset choices the Algorithm is making, read the documentation.
        * Once you choose an Algorithm, click on execute. 
            * It will take you to page with a description and you will have to choose a Job Name, a workset for analysis, and any additional choices relevant to the algorithm you are choosing. 
    * Once you make your choices, you will go to a page listing [current and past Jobs.](https://analytics.hathitrust.org/listjobs)
        * Click on the Job name to see the output.         


* Workset review!
    * How did it go?
    * What kind of search criteria did you use?
    * Did you find any challenges?
    * Remember you can always click on Read Documentation or Learn More to find additional contextual information. 

## All HTRC Tutorials
*  [A comprehensive list of all HTRC tutorials to walk you through the steps for using HTRC tools and data.](https://wiki.htrc.illinois.edu/display/COM/All+HTRC+Tutorials)

# Lessons
[Library Carpentry lesson on fetching data from APIs.](https://joshuadull.github.io/APIs-for-Libraries/)

Some content in this session based on [HTRC Digging Deeper, Reaching Further](https://teach.htrc.illinois.edu/teaching-materials/) used under a [Creative Commons Attribution-NonCommercial 4.0 International License.](https://creativecommons.org/licenses/by-nc/4.0/)

